<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>EditFaceTalker: 可编辑的面部表情驱动的说话人合成</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
</head>
<body>
    <header>
        <div class="title-container">
            <h1>EditFaceTalker: 可编辑的面部表情驱动的说话人合成</h1>
            <div class="authors">
                <p>张三<sup>1</sup>, 李四<sup>1</sup>, 王五<sup>2</sup>, 赵六<sup>1</sup></p>
                <p class="affiliations"><sup>1</sup>某某大学计算机科学与技术学院, <sup>2</sup>某某研究院人工智能实验室</p>
            </div>
        </div>
        <div class="buttons-container">
            <a href="#" class="button paper-button"><i class="fas fa-file-alt"></i> 论文</a>
            <a href="#" class="button code-button"><i class="fas fa-code"></i> 代码</a>
            <a href="#" class="button project-button"><i class="fas fa-home"></i> 项目主页</a>
        </div>
    </header>

    <section id="abstract">
        <h2>摘要</h2>
        <div class="content-box">
            <p>本研究提出了一种新型的可编辑面部表情驱动的说话人合成方法——EditFaceTalker。我们的方法能够根据输入的音频和参考图像，生成高质量的说话视频，同时允许用户对面部表情进行精细控制和编辑。与现有方法相比，我们的方法在保持口型同步准确性的同时，显著提高了面部表情的自然度和多样性。通过引入创新的表情解耦模块和自适应融合网络，我们实现了对面部属性的精确控制，包括情绪表达、头部姿态和眼部动作等。大量实验表明，我们的方法在主观和客观评价指标上均优于现有最先进的技术，为虚拟人物动画、视频会议和数字内容创作等领域提供了新的可能性。</p>
        </div>
    </section>

    <section id="overview">
        <h2>技术架构</h2>
        <div class="content-box">
            <div class="overview-image">
                <img src="images/architecture.png" alt="EditFaceTalker 技术架构图">
                <p class="caption">图1: EditFaceTalker 方法架构概览。我们的方法包含三个主要模块：(a) 音频特征提取器，(b) 表情解耦编码器，以及 (c) 表情可控生成器。</p>
            </div>
            <div class="overview-description">
                <p>如图1所示，EditFaceTalker由三个主要组件构成：</p>
                <ol>
                    <li><strong>音频特征提取器</strong>：将输入音频转换为时序语音特征，捕捉发音和韵律信息。</li>
                    <li><strong>表情解耦编码器</strong>：从参考图像中提取并解耦面部身份、情绪和姿态特征。</li>
                    <li><strong>表情可控生成器</strong>：整合音频特征和解耦的面部特征，生成自然、流畅且表情可控的说话视频。</li>
                </ol>
                <p>我们的方法支持多种面部属性的精细编辑，包括情绪表达（如高兴、悲伤、惊讶等）、头部姿态调整以及眼部动作控制，同时保持口型与音频的精确同步。</p>
            </div>
        </div>
    </section>

    <section id="comparison">
        <h2>质量比较</h2>
        <div class="content-box">
            <p class="section-intro">我们将EditFaceTalker与当前最先进的几种方法进行了比较，包括Wav2Lip, MakeItTalk, 和 Audio2Head。</p>
            
            <div class="comparison-grid">
                <div class="comparison-item">
                    <h3>视觉质量比较</h3>
                    <div class="comparison-video">
                        <video controls>
                            <source src="videos/quality_comparison.mp4" type="video/mp4">
                            您的浏览器不支持视频标签。
                        </video>
                    </div>
                    <p class="caption">图2: 与现有方法的视觉质量比较。从左到右依次为：原始视频、Wav2Lip、MakeItTalk、Audio2Head和我们的EditFaceTalker。</p>
                </div>
                
                <div class="comparison-item">
                    <h3>口型同步精度</h3>
                    <!-- <div class="comparison-image">
                        <img src="images/lip_sync_comparison.png" alt="口型同步精度比较">
                    </div> -->
                    <div class="comparison-video">
                        <video controls>
                            <source src="videos/quality_comparison.mp4" type="video/mp4">
                            您的浏览器不支持视频标签。
                        </video>
                    </div>
                    <p class="caption">图3: 不同方法的口型同步精度比较。我们的方法在LSE-D和LSE-C指标上均取得最佳结果。</p>
                </div>
            </div>
            
            <div class="comparison-table">
                <h3>定量评估结果</h3>
                <table>
                    <thead>
                        <tr>
                            <th>方法</th>
                            <th>LSE-D ↓</th>
                            <th>LSE-C ↑</th>
                            <th>FID ↓</th>
                            <th>用户偏好 ↑</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Wav2Lip</td>
                            <td>7.42</td>
                            <td>6.91</td>
                            <td>38.54</td>
                            <td>18.3%</td>
                        </tr>
                        <tr>
                            <td>MakeItTalk</td>
                            <td>9.56</td>
                            <td>5.23</td>
                            <td>42.17</td>
                            <td>12.7%</td>
                        </tr>
                        <tr>
                            <td>Audio2Head</td>
                            <td>6.89</td>
                            <td>7.12</td>
                            <td>35.21</td>
                            <td>23.5%</td>
                        </tr>
                        <tr class="our-method">
                            <td>EditFaceTalker (Ours)</td>
                            <td><strong>5.17</strong></td>
                            <td><strong>8.45</strong></td>
                            <td><strong>29.83</strong></td>
                            <td><strong>45.5%</strong></td>
                        </tr>
                    </tbody>
                </table>
                <p class="caption">表1: 不同方法的定量评估结果。LSE-D: 口型同步误差距离; LSE-C: 口型同步误差置信度; FID: Fréchet Inception Distance; 用户偏好: 人类评估中的偏好百分比。</p>
            </div>
        </div>
    </section>

    <section id="emotional-results">
        <h2>属性编辑生成</h2>
        <div class="content-box">
            <p class="section-intro">EditFaceTalker能够生成具有不同面部属性的说话视频。以下展示了同一音频输入和身份下，通过调整不同面部属性参数生成的结果。</p>
            
            <div class="emotion-grid">
                <div class="emotion-item">
                    <h3>中性 (Neutral)</h3>
                    <video controls>
                        <source src="videos/emotion_neutral.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
                <div class="emotion-item">
                    <h3>高兴 (Happy)</h3>
                    <video controls>
                        <source src="videos/emotion_happy.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
                <div class="emotion-item">
                    <h3>悲伤 (Sad)</h3>
                    <video controls>
                        <source src="videos/emotion_sad.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
                <div class="emotion-item">
                    <h3>惊讶 (Surprised)</h3>
                    <video controls>
                        <source src="videos/emotion_surprised.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
                <div class="emotion-item">
                    <h3>愤怒 (Angry)</h3>
                    <video controls>
                        <source src="videos/emotion_angry.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
                <div class="emotion-item">
                    <h3>恐惧 (Fear)</h3>
                    <video controls>
                        <source src="videos/emotion_fear.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
                <div class="emotion-item">
                    <h3>厌恶 (Disgust)</h3>
                    <video controls>
                        <source src="videos/emotion_disgust.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
                <div class="emotion-item">
                    <h3>沉思 (Contemplative)</h3>
                    <video controls>
                        <source src="videos/emotion_contemplative.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
                <div class="emotion-item">
                    <h3>困惑 (Confused)</h3>
                    <video controls>
                        <source src="videos/emotion_confused.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
                <div class="emotion-item">
                    <h3>自信 (Confident)</h3>
                    <video controls>
                        <source src="videos/emotion_confident.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
                <div class="emotion-item">
                    <h3>自信 (Confident)</h3>
                    <video controls>
                        <source src="videos/emotion_confident.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
                <div class="emotion-item">
                    <h3>自信 (Confident)</h3>
                    <video controls>
                        <source src="videos/emotion_confident.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
            </div>
            
            <div class="attribute-control">
                <h3>头部姿态控制</h3>
                <div class="attribute-video">
                    <video controls>
                        <source src="videos/head_pose_control.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
                <p class="caption">图4: 通过调整头部姿态参数，可以控制生成视频中的头部运动。</p>
            </div>
            
            <div class="attribute-control">
                <h3>眼部动作控制</h3>
                <div class="attribute-video">
                    <video controls>
                        <source src="videos/eye_movement_control.mp4" type="video/mp4">
                        您的浏览器不支持视频标签。
                    </video>
                </div>
                <p class="caption">图5: 通过调整眼部参数，可以控制生成视频中的眨眼频率和视线方向。</p>
            </div>
        </div>
    </section>

    <section id="bibtex">
        <h2>BibTeX</h2>
        <div class="content-box">
            <pre><code>@inproceedings{zhang2023editfacetalker,
  title={EditFaceTalker: 可编辑的面部表情驱动的说话人合成},
  author={张三 and 李四 and 王五 and 赵六},
  booktitle={计算机视觉与模式识别会议论文集},
  pages={1234--1243},
  year={2023}
}</code></pre>
        </div>
    </section>

    <footer>
        <p>&copy; 2023 某某大学计算机科学与技术学院. 保留所有权利。</p>
    </footer>

    <script src="script.js"></script>
</body>
</html>